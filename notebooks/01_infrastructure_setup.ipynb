{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Infrastructure Setup\n",
    "\n",
    "This notebook sets up the Databricks infrastructure:\n",
    "- Install custom SFTP data source package\n",
    "- Configure storage credentials\n",
    "- Set up Databricks secrets\n",
    "- Verify connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Custom SFTP Data Source Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies from requirements.txt\n%pip install -r /Workspace/Repos/<your-repo>/databricks-sftp-data-source/requirements.txt\n\n# Install the custom SFTP package\n%pip install -e /Workspace/Repos/<your-repo>/databricks-sftp-data-source\n\ndbutils.library.restartPython()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pyspark.sql import SparkSession\nfrom ingest import SFTPWriter, SFTPDataSource\nimport json"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Databricks Secrets\n",
    "\n",
    "Store sensitive credentials in Databricks secrets. Run these commands in Databricks CLI:\n",
    "\n",
    "```bash\n",
    "# Create secret scope\n",
    "databricks secrets create-scope --scope sftp-credentials\n",
    "\n",
    "# Store source SFTP credentials\n",
    "databricks secrets put --scope sftp-credentials --key source-host\n",
    "databricks secrets put --scope sftp-credentials --key source-username\n",
    "databricks secrets put --scope sftp-credentials --key source-private-key\n",
    "\n",
    "# Store target SFTP credentials\n",
    "databricks secrets put --scope sftp-credentials --key target-host\n",
    "databricks secrets put --scope sftp-credentials --key target-username\n",
    "databricks secrets put --scope sftp-credentials --key target-private-key\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload SSH Private Key to Databricks\n",
    "\n",
    "Upload the private key file to DBFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for SSH keys\n",
    "dbutils.fs.mkdirs(\"/FileStore/ssh-keys\")\n",
    "\n",
    "# Upload private key using Databricks CLI:\n",
    "# databricks fs cp ~/.ssh/sftp_key dbfs:/FileStore/ssh-keys/sftp_key\n",
    "\n",
    "print(\"Upload SSH private key to: dbfs:/FileStore/ssh-keys/sftp_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure SFTP Connection Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source SFTP configuration\n",
    "source_config = {\n",
    "    \"host\": dbutils.secrets.get(scope=\"sftp-credentials\", key=\"source-host\"),\n",
    "    \"username\": dbutils.secrets.get(scope=\"sftp-credentials\", key=\"source-username\"),\n",
    "    \"private_key_path\": \"/dbfs/FileStore/ssh-keys/sftp_key\",\n",
    "    \"port\": 22\n",
    "}\n",
    "\n",
    "# Target SFTP configuration\n",
    "target_config = {\n",
    "    \"host\": dbutils.secrets.get(scope=\"sftp-credentials\", key=\"target-host\"),\n",
    "    \"username\": dbutils.secrets.get(scope=\"sftp-credentials\", key=\"target-username\"),\n",
    "    \"private_key_path\": \"/dbfs/FileStore/ssh-keys/sftp_key\",\n",
    "    \"port\": 22\n",
    "}\n",
    "\n",
    "print(\"SFTP configurations loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Source SFTP Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection to source SFTP\n",
    "source_writer = SFTPDataSource.create_writer(source_config)\n",
    "\n",
    "with source_writer.session():\n",
    "    files = source_writer.list_files(\".\")\n",
    "    print(\"Source SFTP files:\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Target SFTP Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection to target SFTP\n",
    "target_writer = SFTPDataSource.create_writer(target_config)\n",
    "\n",
    "with target_writer.session():\n",
    "    files = target_writer.list_files(\".\")\n",
    "    print(\"Target SFTP files:\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Configuration to Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create catalog and schema for configuration\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS sftp_demo\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS sftp_demo.config\")\n",
    "\n",
    "# Store configuration (without sensitive data)\n",
    "config_data = [\n",
    "    (\"source_host\", source_config[\"host\"]),\n",
    "    (\"source_username\", source_config[\"username\"]),\n",
    "    (\"target_host\", target_config[\"host\"]),\n",
    "    (\"target_username\", target_config[\"username\"]),\n",
    "    (\"ssh_key_path\", \"/dbfs/FileStore/ssh-keys/sftp_key\")\n",
    "]\n",
    "\n",
    "config_df = spark.createDataFrame(config_data, [\"key\", \"value\"])\n",
    "config_df.write.mode(\"overwrite\").saveAsTable(\"sftp_demo.config.connection_params\")\n",
    "\n",
    "print(\"Configuration saved to sftp_demo.config.connection_params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Verify Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display configuration\n",
    "display(spark.table(\"sftp_demo.config.connection_params\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Infrastructure setup completed:\n",
    "- ✓ Custom SFTP data source package installed\n",
    "- ✓ Databricks secrets configured\n",
    "- ✓ SSH keys uploaded to DBFS\n",
    "- ✓ SFTP connections tested\n",
    "- ✓ Configuration saved to Unity Catalog\n",
    "\n",
    "Next step: Run notebook `02_uc_connection_setup.ipynb` to configure Unity Catalog connections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}