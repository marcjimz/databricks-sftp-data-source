{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 00 - Prerequisites: Azure Storage and SFTP Setup\n\n**IMPORTANT:** This setup is now automated via shell scripts that run on your local machine.\n\n## Prerequisites\n\nBefore running Databricks notebooks, you need to set up Azure infrastructure on your **local machine**:\n\n1. **Azure CLI** installed and configured\n2. **SSH** utilities installed\n3. **Databricks CLI** installed and configured\n\n## Setup Steps (Local Machine)\n\nRun these scripts on your local machine:\n\n### 1. Azure Infrastructure Setup\n```bash\ncd scripts\n./setup_azure_infrastructure.sh\n```\n\nThis script will:\n- Generate SSH key pair\n- Create Azure resource group\n- Create source and target storage accounts with SFTP enabled\n- Create containers\n- Configure SFTP users\n- Upload sample CSV files\n- Display connection details\n\n### 2. Databricks Secrets Setup\n```bash\ncd scripts\n./setup_databricks_secrets.sh\n```\n\nThis script will:\n- Create Databricks secret scope\n- Store SFTP connection details in secrets\n- Upload SSH private key to DBFS\n\n## Next Steps\n\nAfter running the setup scripts, proceed to:\n- **Notebook 01**: `01_infrastructure_setup.ipynb` - Install SFTP package in Databricks\n- **Notebook 02**: `02_uc_connection_setup.ipynb` - Configure Unity Catalog connections\n- **Notebook 03**: `03_dlt_pipeline.ipynb` - Run the DLT pipeline"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}