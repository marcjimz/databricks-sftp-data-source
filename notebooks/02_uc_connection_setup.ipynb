{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1c98bef-c3a9-419f-99a3-4e8516ac4655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 02 - Unity Catalog Connection Setup\n",
    "\n",
    "This notebook configures Unity Catalog connections for SFTP data sources:\n",
    "- Create Unity Catalog connections for source and target SFTP\n",
    "- Test connections using AutoLoader\n",
    "- Configure external locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fb2bd02-fd6b-48a0-8500-293ef9c780a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Load Configuration from Previous Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "689e7c44-774a-4b83-9190-f3a3fef9f575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create widgets for catalog and schema configuration\n",
    "dbutils.widgets.text(\"catalog_name\", \"sftp_demo\", \"Catalog Name\")\n",
    "dbutils.widgets.text(\"schema_name\", \"default\", \"Schema Name\")\n",
    "dbutils.widgets.text(\"source_connection_name\", \"source_sftp_connection\", \"Source Connection Name\")\n",
    "dbutils.widgets.text(\"target_connection_name\", \"target_sftp_connection\", \"Target Connection Name\")\n",
    "\n",
    "# Get widget values\n",
    "CATALOG_NAME = dbutils.widgets.get(\"catalog_name\")\n",
    "SCHEMA_NAME = dbutils.widgets.get(\"schema_name\")\n",
    "SOURCE_CONNECTION_NAME = dbutils.widgets.get(\"source_connection_name\")\n",
    "TARGET_CONNECTION_NAME = dbutils.widgets.get(\"target_connection_name\")\n",
    "\n",
    "print(f\"Catalog: {CATALOG_NAME}\")\n",
    "print(f\"Schema: {SCHEMA_NAME}\")\n",
    "print(f\"Source Connection: {SOURCE_CONNECTION_NAME}\")\n",
    "print(f\"Target Connection: {TARGET_CONNECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60e439d2-9996-46a5-9dd5-70458dff8abc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_df = spark.table(f\"{CATALOG_NAME}.{SCHEMA_NAME}.connection_params\")\n",
    "config_dict = {row.key: row.value for row in config_df.collect()}\n",
    "\n",
    "# Get configuration values\n",
    "catalog_name = config_dict.get(\"catalog_name\", CATALOG_NAME)\n",
    "schema_name = config_dict.get(\"schema_name\", SCHEMA_NAME)\n",
    "source_connection_name = config_dict.get(\"source_connection_name\", SOURCE_CONNECTION_NAME)\n",
    "target_connection_name = config_dict.get(\"target_connection_name\", TARGET_CONNECTION_NAME)\n",
    "\n",
    "source_host = config_dict[\"source_host\"]\n",
    "source_username = config_dict[\"source_username\"]\n",
    "target_host = config_dict[\"target_host\"]\n",
    "target_username = config_dict[\"target_username\"]\n",
    "secret_scope = config_dict[\"secret_scope\"]\n",
    "ssh_key_secret = config_dict[\"ssh_key_secret\"]\n",
    "\n",
    "print(\"Configuration loaded successfully\")\n",
    "print(f\"Catalog: {catalog_name}\")\n",
    "print(f\"Schema: {schema_name}\")\n",
    "print(f\"Source Connection: {source_connection_name}\")\n",
    "print(f\"Target Connection: {target_connection_name}\")\n",
    "print(f\"Secret scope: {secret_scope}\")\n",
    "print(f\"SSH key secret: {ssh_key_secret}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbe6960b-3ff0-481a-b062-19c233ffaf1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Create Unity Catalog Connection for Source SFTP\n",
    "\n",
    "**Note:** This requires Databricks workspace admin privileges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c9fcd2-8450-49e7-be8c-1fd60bc7b0eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set catalog context first\n",
    "spark.sql(f\"USE CATALOG {CATALOG_NAME}\")\n",
    "\n",
    "# Create source SFTP connection using correct syntax\n",
    "# Note: Unity Catalog requires 'user' and 'pem_private_key' (not 'username' and 'privateKey')\n",
    "spark.sql(f\"\"\"\n",
    "CREATE CONNECTION IF NOT EXISTS {SOURCE_CONNECTION_NAME}\n",
    "TYPE sftp\n",
    "OPTIONS (\n",
    "  host '{source_host}',\n",
    "  port '22',\n",
    "  user SECRET ('{secret_scope}', 'source-username'),\n",
    "  pem_private_key SECRET ('{secret_scope}', '{ssh_key_secret}')\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Source SFTP connection created: {CATALOG_NAME}.{SOURCE_CONNECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1b67ba7-9f58-4a41-8fcd-d416b35ab112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Create Unity Catalog Connection for Target SFTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ccdf1f2-96f5-409c-8ea2-e22da18eb70c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create target SFTP connection using correct syntax\n",
    "spark.sql(f\"\"\"\n",
    "CREATE CONNECTION IF NOT EXISTS {TARGET_CONNECTION_NAME}\n",
    "TYPE sftp\n",
    "OPTIONS (\n",
    "  host '{target_host}',\n",
    "  port '22',\n",
    "  user SECRET ('{secret_scope}', 'target-username'),\n",
    "  pem_private_key SECRET ('{secret_scope}', '{ssh_key_secret}')\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Target SFTP connection created: {CATALOG_NAME}.{TARGET_CONNECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81c45299-d721-4ee6-82f1-1f2361c60dd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Verify Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5211491d-c978-40a4-b016-1e40216ef3b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Correct path format: sftp://username@host:port/absolute_path\n",
    "df = (\n",
    "    spark.readStream\n",
    "    .format(\"cloudFiles\")  # Must use cloudFiles, not just \"csv\"\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"cloudFiles.schemaLocation\", \"/path/to/schema/location\")\n",
    "    # Path must include username and absolute path from root /\n",
    "    .load(f\"sftp://{source_username}@{source_host}:22/customers.csv\")\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", \"/path/to/checkpoint\")\n",
    "    .trigger(availableNow=True)\n",
    "    .table(\"my_table\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e7d773f-faa1-4f0b-9fb9-41117e44fe6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "GRANT USAGE ON CONNECTION source_sftp_connection \n",
    "TO `marcin.jimenez@databricks.com`\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cf5cb09-7f96-4d2c-b8c9-6c9c477c3cc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test with batch read (simpler than streaming)\n",
    "try:\n",
    "    test_df = (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"connectionName\", f\"{CATALOG_NAME}.source_sftp_connection\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(f\"sftp://{source_username}@{source_host}:22/customers.csv\")  # Try without username in path\n",
    "    )\n",
    "    \n",
    "    test_df.display()\n",
    "    print(\"✅ Batch read successful!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Batch read failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fbb75b9-ca59-4fb5-a627-273db846ed7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test reading customers.csv from source SFTP\n",
    "source_path = f\"sftp://{source_username}@{source_host}:22/customers.csv\"\n",
    "\n",
    "customers_df = (\n",
    "    spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"cloudFiles.connectionName\", f\"{CATALOG_NAME}.source_sftp_connection\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(source_path)\n",
    ")\n",
    "\n",
    "# Display schema\n",
    "customers_df.printSchema()\n",
    "\n",
    "# Write to temporary table for verification\n",
    "(\n",
    "    customers_df.writeStream\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"test_customers\")\n",
    "    .outputMode(\"append\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "print(\"Source SFTP connection verified successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0d48f06-d290-4d81-806b-23f55601b9b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Test Source Connection with AutoLoader\n",
    "\n",
    "Read data from source SFTP using AutoLoader to verify the connection works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33493a23-729f-48bd-83fe-430ce1034e58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "display(spark.sql(\"SELECT * FROM test_customers LIMIT 10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4112e368-d207-441c-88cc-40bf80b0d5eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test reading customers.csv from source SFTP\n",
    "source_path = f\"sftp://{source_host}/customers.csv\"\n",
    "\n",
    "customers_df = (\n",
    "    spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"cloudFiles.connectionName\", f\"{CATALOG_NAME}.{SOURCE_CONNECTION_NAME}\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(source_path)\n",
    ")\n",
    "\n",
    "# Display schema\n",
    "customers_df.printSchema()\n",
    "\n",
    "# Write to temporary table for verification\n",
    "(\n",
    "    customers_df.writeStream\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"test_customers\")\n",
    "    .outputMode(\"append\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "print(\"Source SFTP connection verified successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6fb13c6-6381-404e-b02f-e93a841d33e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create catalog structure for DLT pipeline\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG_NAME}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.bronze\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.silver\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.gold\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}\")\n",
    "\n",
    "print(\"Catalog structure created:\")\n",
    "print(f\"  - {CATALOG_NAME}.bronze (raw data from source SFTP)\")\n",
    "print(f\"  - {CATALOG_NAME}.silver (cleaned and validated data)\")\n",
    "print(f\"  - {CATALOG_NAME}.gold (aggregated business-level data)\")\n",
    "print(f\"  - {CATALOG_NAME}.{SCHEMA_NAME} (default schema)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b9709d0-9444-49af-8c50-4f50e16735dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8. Create External Location for Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "717d5721-087b-41b3-91be-0d6f97420533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create checkpoint location in DBFS\n",
    "checkpoint_location = f\"/dbfs/{CATALOG_NAME}/checkpoints\"\n",
    "dbutils.fs.mkdirs(checkpoint_location)\n",
    "\n",
    "print(f\"Checkpoint location created: {checkpoint_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3147d9e5-2f01-44b5-b1fa-1814ac81b7c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 9. Grant Permissions (if needed)\n",
    "\n",
    "Grant necessary permissions to use the connections in DLT pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e64b937a-1938-43e3-b8bf-2aaa6fb45576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Grant USAGE on connections to all users (adjust as needed)\n",
    "# Uncomment if you need to grant permissions:\n",
    "\n",
    "# spark.sql(f\"\"\"\n",
    "# GRANT USAGE ON CONNECTION {CATALOG_NAME}.source_sftp_connection \n",
    "# TO `account users`\n",
    "# \"\"\")\n",
    "\n",
    "# spark.sql(f\"\"\"\n",
    "# GRANT USAGE ON CONNECTION {CATALOG_NAME}.target_sftp_connection \n",
    "# TO `account users`\n",
    "# \"\"\")\n",
    "\n",
    "print(\"Connection permissions configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c3c49da-7eec-4eba-86d7-8419bfa50f64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 10. Test Complete Data Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76e8d827-0493-423f-a8ed-2ba727efc340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read orders.csv from source SFTP\n",
    "orders_path = f\"sftp://{source_host}/orders.csv\"\n",
    "\n",
    "orders_df = (\n",
    "    spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"cloudFiles.connectionName\", f\"{CATALOG_NAME}.source_sftp_connection\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(orders_path)\n",
    ")\n",
    "\n",
    "# Display schema\n",
    "orders_df.printSchema()\n",
    "\n",
    "# Write to temporary table\n",
    "(\n",
    "    orders_df.writeStream\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"test_orders\")\n",
    "    .outputMode(\"append\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "print(\"Orders data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "157fc9a2-d546-45a9-82b8-4972bf837cdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display sample orders data\n",
    "display(spark.sql(\"SELECT * FROM test_orders LIMIT 10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "222ddb5d-79b2-4473-97b6-fbb49b62fc34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Read orders.csv from source SFTP\n",
    "orders_path = f\"sftp://{source_host}/orders.csv\"\n",
    "\n",
    "orders_df = (\n",
    "    spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"cloudFiles.connectionName\", f\"{CATALOG_NAME}.{SOURCE_CONNECTION_NAME}\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(orders_path)\n",
    ")\n",
    "\n",
    "# Display schema\n",
    "orders_df.printSchema()\n",
    "\n",
    "# Write to temporary table\n",
    "(\n",
    "    orders_df.writeStream\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"test_orders\")\n",
    "    .outputMode(\"append\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "print(\"Orders data loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_uc_connection_setup",
   "widgets": {
    "catalog_name": {
     "currentValue": "sftp_demo",
     "nuid": "db34bd33-38e4-4f9d-8d6b-7fb16946d07c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "sftp_demo",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "sftp_demo",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema_name": {
     "currentValue": "default",
     "nuid": "cbbc9a4e-3cbf-46a3-8c21-ce0f12097d27",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "default",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "source_connection_name": {
     "currentValue": "source_sftp_connection",
     "nuid": "4ecdf67a-70b9-4910-b4e6-a822a61ec3e5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "source_sftp_connection",
      "label": "Source Connection Name",
      "name": "source_connection_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "source_sftp_connection",
      "label": "Source Connection Name",
      "name": "source_connection_name",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "target_connection_name": {
     "currentValue": "target_sftp_connection",
     "nuid": "e253f410-6f6d-4144-8ecc-a3074cb077aa",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "target_sftp_connection",
      "label": "Target Connection Name",
      "name": "target_connection_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "target_sftp_connection",
      "label": "Target Connection Name",
      "name": "target_connection_name",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
