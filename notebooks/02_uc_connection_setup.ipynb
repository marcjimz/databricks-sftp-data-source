{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1c98bef-c3a9-419f-99a3-4e8516ac4655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 02 - Unity Catalog Connection Setup\n",
    "\n",
    "This notebook configures Unity Catalog connections for SFTP data sources and verifies AutoLoader can read from SFTP.\n",
    "\n",
    "**Note:** AutoLoader with SFTP is straightforward and built-in to Databricks. The main purpose of this repository is to demonstrate the **custom SFTPWriter** for writing data back to SFTP servers.\n",
    "\n",
    "This notebook will:\n",
    "- Create Unity Catalog SFTP connections (stores credentials securely)\n",
    "- Verify AutoLoader can read from SFTP using simple URI format\n",
    "- Create catalog and schema structure for the DLT pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fb2bd02-fd6b-48a0-8500-293ef9c780a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Load Configuration from Previous Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "689e7c44-774a-4b83-9190-f3a3fef9f575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create widgets for catalog and schema configuration\n",
    "dbutils.widgets.text(\"catalog_name\", \"sftp_demo\", \"Catalog Name\")\n",
    "dbutils.widgets.text(\"schema_name\", \"default\", \"Schema Name\")\n",
    "dbutils.widgets.text(\"source_connection_name\", \"source_sftp_connection\", \"Source Connection Name\")\n",
    "dbutils.widgets.text(\"target_connection_name\", \"target_sftp_connection\", \"Target Connection Name\")\n",
    "\n",
    "# Get widget values\n",
    "CATALOG_NAME = dbutils.widgets.get(\"catalog_name\")\n",
    "SCHEMA_NAME = dbutils.widgets.get(\"schema_name\")\n",
    "SOURCE_CONNECTION_NAME = dbutils.widgets.get(\"source_connection_name\")\n",
    "TARGET_CONNECTION_NAME = dbutils.widgets.get(\"target_connection_name\")\n",
    "\n",
    "print(f\"Catalog: {CATALOG_NAME}\")\n",
    "print(f\"Schema: {SCHEMA_NAME}\")\n",
    "print(f\"Source Connection: {SOURCE_CONNECTION_NAME}\")\n",
    "print(f\"Target Connection: {TARGET_CONNECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60e439d2-9996-46a5-9dd5-70458dff8abc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_df = spark.table(f\"{CATALOG_NAME}.config.connection_params\")\n",
    "config_dict = {row.key: row.value for row in config_df.collect()}\n",
    "\n",
    "# Get configuration values\n",
    "catalog_name = config_dict.get(\"catalog_name\", CATALOG_NAME)\n",
    "schema_name = config_dict.get(\"schema_name\", SCHEMA_NAME)\n",
    "source_connection_name = config_dict.get(\"source_connection_name\", SOURCE_CONNECTION_NAME)\n",
    "target_connection_name = config_dict.get(\"target_connection_name\", TARGET_CONNECTION_NAME)\n",
    "\n",
    "source_host = config_dict[\"source_host\"]\n",
    "source_username = config_dict[\"source_username\"]\n",
    "target_host = config_dict[\"target_host\"]\n",
    "target_username = config_dict[\"target_username\"]\n",
    "secret_scope = config_dict[\"secret_scope\"]\n",
    "ssh_key_secret = config_dict[\"ssh_key_secret\"]\n",
    "ssh_key_fingerprint = config_dict[\"ssh_key_fingerprint\"]\n",
    "\n",
    "print(\"Configuration loaded successfully\")\n",
    "print(f\"Catalog: {catalog_name}\")\n",
    "print(f\"Schema: {schema_name}\")\n",
    "print(f\"Source Connection: {source_connection_name}\")\n",
    "print(f\"Target Connection: {target_connection_name}\")\n",
    "print(f\"Secret scope: {secret_scope}\")\n",
    "print(f\"SSH key secret: {ssh_key_secret}\")\n",
    "print(f\"SSH key fingerprint: {ssh_key_fingerprint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbe6960b-3ff0-481a-b062-19c233ffaf1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Create Unity Catalog Connection for Source SFTP\n",
    "\n",
    "**Note:** This requires Databricks workspace admin privileges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c9fcd2-8450-49e7-be8c-1fd60bc7b0eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set catalog context first\n",
    "spark.sql(f\"USE CATALOG {CATALOG_NAME}\")\n",
    "\n",
    "# Debug: Print the values being used\n",
    "print(\"Creating source SFTP connection with:\")\n",
    "print(f\"  host: {source_host}\")\n",
    "print(f\"  port: 22\")\n",
    "print(f\"  user: SECRET('{secret_scope}', 'source-username')\")\n",
    "print(f\"  pem_private_key: SECRET('{secret_scope}', '{ssh_key_secret}')\")\n",
    "print(f\"  key_fingerprint: {ssh_key_fingerprint}\")\n",
    "\n",
    "# Build the SQL statement\n",
    "create_source_sql = f\"\"\"\n",
    "CREATE CONNECTION IF NOT EXISTS {SOURCE_CONNECTION_NAME}\n",
    "TYPE sftp\n",
    "OPTIONS (\n",
    "  host '{source_host}',\n",
    "  port '22',\n",
    "  user SECRET ('{secret_scope}', 'source-username'),\n",
    "  pem_private_key SECRET ('{secret_scope}', '{ssh_key_secret}'),\n",
    "  key_fingerprint '{ssh_key_fingerprint}'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nExecuting SQL:\")\n",
    "print(create_source_sql)\n",
    "\n",
    "# Create source SFTP connection\n",
    "spark.sql(create_source_sql)\n",
    "\n",
    "print(f\"\\n✓ Source SFTP connection created: {SOURCE_CONNECTION_NAME} (in catalog {CATALOG_NAME})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1b67ba7-9f58-4a41-8fcd-d416b35ab112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Create Unity Catalog Connection for Target SFTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ccdf1f2-96f5-409c-8ea2-e22da18eb70c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Debug: Print the values being used\n",
    "print(\"Creating target SFTP connection with:\")\n",
    "print(f\"  host: {target_host}\")\n",
    "print(f\"  port: 22\")\n",
    "print(f\"  user: SECRET('{secret_scope}', 'target-username')\")\n",
    "print(f\"  pem_private_key: SECRET('{secret_scope}', '{ssh_key_secret}')\")\n",
    "print(f\"  key_fingerprint: {ssh_key_fingerprint}\")\n",
    "\n",
    "# Build the SQL statement\n",
    "create_target_sql = f\"\"\"\n",
    "CREATE CONNECTION IF NOT EXISTS {TARGET_CONNECTION_NAME}\n",
    "TYPE sftp\n",
    "OPTIONS (\n",
    "  host '{target_host}',\n",
    "  port '22',\n",
    "  user SECRET ('{secret_scope}', 'target-username'),\n",
    "  pem_private_key SECRET ('{secret_scope}', '{ssh_key_secret}'),\n",
    "  key_fingerprint '{ssh_key_fingerprint}'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nExecuting SQL:\")\n",
    "print(create_target_sql)\n",
    "\n",
    "# Create target SFTP connection\n",
    "spark.sql(create_target_sql)\n",
    "\n",
    "print(f\"\\n✓ Target SFTP connection created: {TARGET_CONNECTION_NAME} (in catalog {CATALOG_NAME})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Verify AutoLoader with SFTP\n\nAutoLoader automatically finds the Unity Catalog connection based on the host in the SFTP URI.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6fb13c6-6381-404e-b02f-e93a841d33e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# Test reading customers.csv from source SFTP using AutoLoader\n# AutoLoader automatically finds the connection based on the host in the URI\nsource_sftp_uri = f\"sftp://{source_username}@{source_host}:22/customers.csv\"\n\ncustomers_df = (\n    spark.readStream\n    .format(\"cloudFiles\")\n    .option(\"cloudFiles.format\", \"csv\")\n    .option(\"cloudFiles.schemaLocation\", f\"/tmp/{CATALOG_NAME}/schema/customers\")\n    .option(\"header\", \"true\")\n    .load(source_sftp_uri)\n)\n\n# Display schema\ncustomers_df.printSchema()\n\n# Write to temporary table for verification\n(\n    customers_df.writeStream\n    .format(\"memory\")\n    .queryName(\"test_customers\")\n    .outputMode(\"append\")\n    .start()\n)\n\nprint(f\"✓ Source SFTP AutoLoader verified successfully\")\nprint(f\"  URI: {source_sftp_uri}\")\nprint(f\"  Connection matched automatically by host: {source_host}\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Create Catalog Structure for DLT Pipeline",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create catalog structure for DLT pipeline\nspark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG_NAME}\")\nspark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.bronze\")\nspark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.silver\")\nspark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.gold\")\nspark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}\")\n\nprint(\"Catalog structure created:\")\nprint(f\"  - {CATALOG_NAME}.bronze (raw data from source SFTP)\")\nprint(f\"  - {CATALOG_NAME}.silver (cleaned and validated data)\")\nprint(f\"  - {CATALOG_NAME}.gold (aggregated business-level data)\")\nprint(f\"  - {CATALOG_NAME}.{SCHEMA_NAME} (default schema)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_uc_connection_setup",
   "widgets": {
    "catalog_name": {
     "currentValue": "sftp_demo",
     "nuid": "db34bd33-38e4-4f9d-8d6b-7fb16946d07c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "sftp_demo",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "sftp_demo",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "schema_name": {
     "currentValue": "default",
     "nuid": "cbbc9a4e-3cbf-46a3-8c21-ce0f12097d27",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "default",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "source_connection_name": {
     "currentValue": "source_sftp_connection",
     "nuid": "4ecdf67a-70b9-4910-b4e6-a822a61ec3e5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "source_sftp_connection",
      "label": "Source Connection Name",
      "name": "source_connection_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "source_sftp_connection",
      "label": "Source Connection Name",
      "name": "source_connection_name",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "target_connection_name": {
     "currentValue": "target_sftp_connection",
     "nuid": "e253f410-6f6d-4144-8ecc-a3074cb077aa",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "target_sftp_connection",
      "label": "Target Connection Name",
      "name": "target_connection_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "target_sftp_connection",
      "label": "Target Connection Name",
      "name": "target_connection_name",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}