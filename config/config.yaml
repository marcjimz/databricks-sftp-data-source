# SFTP Data Source Pipeline Configuration
# This file contains non-sensitive configuration values
# Secrets should be stored in Databricks Secrets

# Unity Catalog Configuration
catalog_name: "main"
schema_name: "sftp_pipeline"

# SFTP Connection Names (Unity Catalog connections)
source_sftp_connection: "sftp_source_connection"
target_sftp_connection: "sftp_target_connection"

# Azure Storage Configuration (for SFTP-enabled storage)
source_storage:
  account_name: "sftpsourceacct"  # Replace with your storage account name
  container: "sftp-source"
  path: "/data/input"

target_storage:
  account_name: "sftptargetacct"  # Replace with your storage account name
  container: "sftp-target"
  path: "/data/output"

# SFTP User Configuration
# Note: Actual keys stored in Databricks Secrets
sftp_user:
  username: "sftpuser"
  ssh_key_secret_scope: "sftp-credentials"
  ssh_key_secret_key: "sftp-private-key"

# Delta Table Configuration
tables:
  bronze:
    name: "bronze_sftp_raw"
    checkpoint_location: "/checkpoints/bronze"

  silver:
    name: "silver_sftp_cleaned"
    checkpoint_location: "/checkpoints/silver"

  gold:
    name: "gold_sftp_aggregated"
    checkpoint_location: "/checkpoints/gold"

# Data Quality Expectations
expectations:
  silver:
    - name: "valid_customer_id"
      rule: "customer_id IS NOT NULL"
      action: "warn"
    - name: "valid_email"
      rule: "email LIKE '%@%.%'"
      action: "drop"

  gold:
    - name: "positive_total_amount"
      rule: "total_amount > 0"
      action: "fail"

# AutoLoader Configuration
autoloader:
  format: "csv"
  schema_hints:
    customer_id: "int"
    order_id: "int"
    amount: "double"
  max_files_per_trigger: 1000

# SFTP Writer Configuration
sftp_writer:
  timeout: 30
  max_retries: 3
  buffer_size: 32768  # 32 KB
  output_format: "csv"

# Logging
logging:
  level: "INFO"
  format: "json"
